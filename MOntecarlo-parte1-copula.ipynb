{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MOntecarlo-parte1-copula.ipynb","provenance":[],"authorship_tag":"ABX9TyNuZGleu8PhDh70Qzy/y9Lb"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"P3i7hqCFNsPa"},"source":["# Montecarlo\r\n","La cópula gaussiana es una cópula construida a partir de una distribución normal multivariada. Si quieren ver las matemáticas pueden revisar wikipedia en este link).\r\n","\r\n","El método para generer números aleatorios correlacionados con una cópula gaussiana es el siguiente:\r\n","\r\n","A partir de la matriz de correlación calculamos la matriz $L$(descomposición de Cholesky).\r\n","Generamos una matriz $x$ de números aleatorios independientes con distribución $N(0,1)$.\r\n","Calculamos la matriz $s = x * L^T$.\r\n","Aplicamos la función de distribución acumulativa normal $\\phi$ a la matriz $s$, de la forma: $U = \\phi(s)$.\r\n","Aplicamos la función de distribución que querramos a cada columna de $U$.\r\n","Ahora vamos a mostrar un ejemplo =D. Empezamos cargando una información de precios y calculamos su matriz de correlacion:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":374},"id":"E2MO8cpKNiow","executionInfo":{"status":"error","timestamp":1607631653338,"user_tz":300,"elapsed":1448,"user":{"displayName":"Wuilson A Estacio R","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giq8fUPFoQg69_EUnX_AOA-zcExx91-WRU0b9liDe8=s64","userId":"12432426679097522768"}},"outputId":"f2de3157-c7f4-42cc-9aad-5cc3d4106532"},"source":["import numpy as np\r\n","import scipy.stats as st\r\n","import pandas as pd\r\n","\r\n","#data = pd.read_excel('Data Prices.xlsx', index_col = 0).sort_index()\r\n","data = pd.read_excel('/content/Data Prices.xlsx', index_col = 0).sort_index()\r\n","data = data.pct_change().dropna().iloc[:,[1,2,6]]\r\n","\r\n","cov = np.cov(data.values.T)\r\n","mu = np.mean(data.values, axis=0)\r\n","desv = np.sqrt(np.diag(cov))\r\n","correl = np.corrcoef(data.values.T)\r\n","\r\n","print(\"Vector de Medias Original:\")\r\n","print(mu)\r\n","print(\"\")\r\n","print(\"Vector de Desviacion Estandar Original:\")\r\n","print(desv)\r\n","print(\"\")\r\n","print(\"Matriz de Covarianza Original:\")\r\n","print(cov)\r\n","print(\"\")\r\n","print(\"Matriz de Correlación Original:\")\r\n","print(correl)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"IndexError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-57775171792c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#data = pd.read_excel('Data Prices.xlsx', index_col = 0).sort_index()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/Data Prices.xlsx'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpct_change\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mcov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcov\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    871\u001b[0m                     \u001b[0;31m# AttributeError for IntervalTree get_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    874\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_valid_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1444\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_has_valid_tuple\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Too many indexers\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 raise ValueError(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_key\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1365\u001b[0m             \u001b[0;31m# check that the key does not exceed the maximum size of the index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen_axis\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlen_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"positional indexers are out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1368\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Can only index by location with a [{self._valid_types}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: positional indexers are out-of-bounds"]}]},{"cell_type":"code","metadata":{"id":"32GVhAbEOnvI"},"source":["%matplotlib inline\r\n","import matplotlib.pyplot as plt\r\n","import seaborn as sns\r\n","\r\n","def hist_scatter(x, y, bins=50):\r\n","    g = sns.JointGrid(x=x, y=y)\r\n","    g = g.plot_joint(sns.scatterplot, color=\"b\", alpha=.6)\r\n","    _ = g.ax_marg_x.hist(x, color=\"r\", alpha=.6,\r\n","                         bins=bins)\r\n","    _ = g.ax_marg_y.hist(y, color=\"green\", alpha=.6,\r\n","                         orientation=\"horizontal\",\r\n","                         bins=bins)\r\n","\r\n","np.random.seed(0)\r\n","x = np.random.randn(1000, 2)\r\n","hist_scatter(x[:,0], x[:,1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LoF90JOyOowg"},"source":["rs = np.random.RandomState(seed = 0)\r\n","n = 10000\r\n","m = data.shape[1]\r\n","x = rs.randn(n, m)\r\n","x = np.matrix(x)\r\n","L = np.linalg.cholesky(correl)\r\n","\r\n","s1 = x * L.T\r\n","U1 = st.norm.cdf(s1)\r\n","\r\n","x1 = st.norm.ppf(U1)\r\n","x1 = np.multiply(x1, desv) + mu\r\n","\r\n","mu_1 = np.mean(x1, axis=0)\r\n","cov_1 = np.cov(x1.T)\r\n","correl_1 = np.corrcoef(x1.T)\r\n","\r\n","print(\"Vector de Medias Original:\")\r\n","print(mu)\r\n","print(\"\")\r\n","print(\"Vector de Medias Simulado:\")\r\n","print(mu_1)\r\n","print(\"\")\r\n","print(\"Matriz de Covarianza Original:\")\r\n","print(cov)\r\n","print(\"\")\r\n","print(\"Matriz de Covarianza Simulada:\")\r\n","print(cov_1)\r\n","print(\"\")\r\n","print(\"Matriz de Correlación Original:\")\r\n","print(correl)\r\n","print(\"\")\r\n","print(\"Matriz de Correlación Simulada:\")\r\n","print(correl_1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EoG93oudOvh0"},"source":["Se puede ver que la serie generada tiene una correlacion similar a la original, sin embargo no es igual. Si graficamos la relación de la primera con segunda columna de $x1$ se obtiene el siguiente grafico"]},{"cell_type":"code","metadata":{"id":"mzQlMqQqOwap"},"source":["#Graficando la relacion de la primera y segunda serie simulada\r\n","hist_scatter(x1[:,0], x1[:,1])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IhseR3S5O5UJ"},"source":["Sin embargo he descubierto un truco para que la correlación generada sea exactamente igual. Para ello se realiza lo siguiente:\r\n","\r\n","Luego de generar la matriz $x$ calculamos su matriz de covarianzas.\r\n","Aplicamos la factorización de Cholesky sobre la matriz de covarianzas y calculamos $L1$.\r\n","Calculamos la inversa de $L1$.\r\n","Actualizamos $x$ con la siguiente formula: $x = x * L1^{-1}$.\r\n","Repetimos este proceso como 3 veces y sobre el nuevo $x$ aplicamos la matriz $L$ del método original.\r\n","Ahora vamos a ver un ejemplo =D para que vean como se hace:"]},{"cell_type":"code","metadata":{"id":"EqTGax0OO6I3"},"source":["x = rs.randn(n, m)\r\n","x = np.matrix(x)\r\n","for i in range(0,3):\r\n","    c1 = np.cov(x.T)\r\n","    L1 = np.linalg.cholesky(c1)\r\n","    L1 = np.matrix(L1).I\r\n","    x = x * L1.T\r\n","\r\n","s2 = x * L.T\r\n","U2 = st.norm.cdf(s2)\r\n","x2 = st.norm.ppf(U2)\r\n","x2 = np.multiply(x2, desv) + mu\r\n","\r\n","mu_2 = np.mean(x2, axis=0)\r\n","cov_2 = np.cov(x2.T)\r\n","correl_2 = np.corrcoef(x2.T)\r\n","\r\n","print(\"Vector de Medias Original:\")\r\n","print(mu)\r\n","print(\"\")\r\n","print(\"Vector de Medias Simulado con el ajuste:\")\r\n","print(mu_2)\r\n","print(\"\")\r\n","print(\"Matriz de Covarianza Original:\")\r\n","print(cov)\r\n","print(\"\")\r\n","print(\"Matriz de Covarianza Simulada con el ajuste:\")\r\n","print(cov_2)\r\n","print(\"\")\r\n","print(\"Matriz de Correlación Original:\")\r\n","print(correl)\r\n","print(\"\")\r\n","print(\"Matriz de Correlación Simulada con el ajuste:\")\r\n","print(correl_2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XkOUYwtDPDXO"},"source":["Ahora podran ver que ambas matrices son identicas, con esto se mejora la precision de la simulación. Si graficamos la relación de la primera con segunda columna de $x2$ se obtiene el siguiente grafico"]},{"cell_type":"code","metadata":{"id":"ANGonUx-PD8t"},"source":["hist_scatter(x2[:,0], x2[:,1])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dmMWkuQQPJLO"},"source":["Ahora para demostrar que podemos generar cualquier tipo de distribución correlacionada, usando la simulación anterior aplicaremos las inversas acumulativas de las distribuciones normal, t y uniforme para calcular las nuevas distribuciones correlacionadas."]},{"cell_type":"code","metadata":{"id":"TGsMnhhiO_gv"},"source":["x3 = st.norm.ppf(U2)\r\n","x3[:,0] = st.norm.ppf(U2[:,0], loc=0.5, scale=0.3)\r\n","x3[:,1] = st.t.ppf(U2[:,1], df = n - 1)\r\n","x3[:,2] = st.uniform.ppf(U2[:,2])\r\n","\r\n","correl_3 = np.corrcoef(x3.T)\r\n","\r\n","print(\"Matriz de Correlación Original:\")\r\n","print(correl)\r\n","print(\"\")\r\n","print(\"Matriz de Correlación Simulada con el ajuste:\")\r\n","print(correl_3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bxUQPtBtPQuo"},"source":["hist_scatter(x3[:,0], x3[:,1])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RlY-ZyqgPT4A"},"source":["Graficando la relacion de la serie con distribucion normal y uniforme\r\n"]},{"cell_type":"code","metadata":{"id":"y_D8Ie9APWDf"},"source":["hist_scatter(x3[:,0], x3[:,2])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QhMp4iTlPcX3"},"source":["Y con eso pueden ver que se han generados muestras de distintas distribuciones correlacionadas."]},{"cell_type":"markdown","metadata":{"id":"yLOqGPC7Pe6g"},"source":["B. Cópula t-Student.\r\n","La cópula t-Student es una cópula construida a partir de una distribución t-Student multivariada. Si quieren ver las matemáticas pueden revisar el paper de este link.\r\n","\r\n","El método para generer números aleatorios correlacionados con una cópula t-Student es el siguiente:\r\n","\r\n","A partir de la matriz de correlación calculamos la matriz $L$(descomposición de Cholesky).\r\n","Calculamos los grados de libertad con la fórmua $\\nu = (n-1)*d$, donde $d$ es el numero de dimensiones y $n$ el número de observaciones a simular.\r\n","Generamos un vector $V$ de dimension de números aleatorios independientes con distribución $\\chi(\\nu)$.\r\n","Generamos una matriz $x$ de números aleatorios independientes con distribución $N(0,1)$.\r\n","Calculamos la matriz $s = \\sqrt{\\frac{\\nu}{V}} * (x * L^T)$.\r\n","Aplicamos la función de distribución acumulativa t-Student $t_{\\nu}$ a la matriz $s$, de la forma: $U = t_{\\nu}(s)$.\r\n","Aplicamos la función de distribución que querramos a cada columna de $U$.\r\n","Ahora vamos a mostrar un ejemplo =D de la simulación con la cópula t-Student:"]},{"cell_type":"code","metadata":{"id":"SiGgmCRSPZIa"},"source":["x = rs.randn(n, m)\r\n","x = np.matrix(x)\r\n","\r\n","v = (n - 1) * m\r\n","V = rs.chisquare(v, size = (n, 1))\r\n","\r\n","s4 = np.sqrt(v/V) * np.array(x * L.T)\r\n","U4 = st.t.cdf(s4, v)\r\n","\r\n","x4 = st.t.ppf(U4, v)\r\n","#x4[:,0] = st.norm.ppf(U4[:,0])\r\n","#x4[:,1] = st.t.ppf(U4[:,1], df = 2)\r\n","#x4[:,2] = st.uniform.ppf(U4[:,2])\r\n","\r\n","correl_4 = np.corrcoef(x4.T)\r\n","\r\n","print(\"Matriz de Correlación Original:\")\r\n","print(correl)\r\n","print(\"\")\r\n","print(\"Matriz de Correlación Simulada sin el ajuste:\")\r\n","print(correl_4)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0okRMWlfPog2"},"source":["\r\n","Se aprecia que al igual que para las copulas gaussianas, la aproximación no es muy buena. Si aplicamos el truco de anterior"]},{"cell_type":"code","metadata":{"id":"oFDjGJo4PpJ2"},"source":["x = rs.randn(n, m)\r\n","x = np.matrix(np.sqrt(v/V) * np.array(x))\r\n","\r\n","for i in range(0,3):\r\n","    c1 = np.cov(x.T)\r\n","    L1 = np.linalg.cholesky(c1)\r\n","    L1 = np.matrix(L1).I\r\n","    x = x * L1.T\r\n","\r\n","s5 = x * L.T\r\n","U5 = st.t.cdf(s5, v)\r\n","\r\n","x5 = st.t.ppf(U5, v)\r\n","\r\n","correl_5 = np.corrcoef(x5.T)\r\n","\r\n","print(\"Matriz de Correlación Original:\")\r\n","print(correl)\r\n","print(\"\")\r\n","print(\"Matriz de Correlación Simulada con el ajuste:\")\r\n","print(correl_5)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y3g-k4E7Pte_"},"source":["Ahora pueden ver que la correlacion ha mejorado comparado a la simulación anterior.\r\n","\r\n","Usando la simulación anterior aplicaremos las inversas acumulativas de las distribuciones normal, t y uniforme para calcular las nuevas distribuciones correlacionadas."]},{"cell_type":"code","metadata":{"id":"gOSyVEW2PuWn"},"source":["x6 = st.t.ppf(U5, v)\r\n","x6[:,0] = st.norm.ppf(U5[:,0])\r\n","x6[:,1] = st.t.ppf(U5[:,1], df = n - 1)\r\n","x6[:,2] = st.uniform.ppf(U5[:,2])\r\n","\r\n","correl_6 = np.corrcoef(x6.T)\r\n","\r\n","print(\"Matriz de Correlación Original:\")\r\n","print(correl)\r\n","print(\"\")\r\n","print(\"Matriz de Correlación Simulada con el ajuste:\")\r\n","print(correl_6)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FKgtZF71P0I3"},"source":["hist_scatter(x6[:,0], x6[:,2])"],"execution_count":null,"outputs":[]}]}